# 服务器
server:
  port: 8071
  session:
    timeout: 1800  # 30 分钟

#模块配置
module: 
  #部署方式
  deploymentType: cluster
  #模块组别，al,rdp,ej,em,etl,config,facade,his。模块应用需要加载的服务，多个角色用逗号分隔
  group: etl
  #模块名称，每个部署的微服务都不一样 
  name: gp2
  snowFlakeSetting: 1-1
  enablemongo: true
  enablekafka: true
  mPointPartitionNum: 10 #kafka分区数量，结合配置
  bPointPartitionNum: 10
  etlPointPartitionNum: 10
  vipAddr:  #双机热备时，vip地址，只有当deploymentType=single时有用

#注册中心
eureka:
  server:
    enableSelfPreservation: false       # 设为false，关闭自我保护
    evictionIntervalTimerInMs: 1000     # 清理间隔（单位毫秒，默认是60*1000）
  instance:
    instance-id: ${spring.cloud.client.ipAddress}:${spring.application.name}:${server.port}
    prefer-ip-address: true
    hostname: ${spring.cloud.client.ipAddress}
  client:
    registerWithEureka: true #是否需要检索服务
    fetchRegistry: true #向注册中心注册自己
    #serviceUrl:
    #  defaultZone: http://admin:123456@${eureka.instance.hostname}:${server.port}/eureka/
    serviceUrl:
      defaultZone: http://admin:123456@localhost:8071/eureka/
      # defaultZone: http://admin:123456@peer1:8761/eureka/,http://admin:123456@peer2:8762/eureka/

# 数据库
druid:
  url: jdbc:mysql://172.16.6.212:3306/iot?useUnicode=true&characterEncoding=utf-8&useSSL=false&serverTimezone=GMT%2B8
  userName: root
  password: 123456

# 配置redis  cluster=false ，说明是单机版的。
redis:
  iscluster: false
# 配置redis 假如用的是 cluster的地址列表 ，用逗号隔开
  cluster:
    host: 192.168.6.102:9001,192.168.6.102:9004,192.168.6.103:9002,192.168.6.103:9005,192.168.6.104:9003,192.168.6.104:9006
# 配置redis 假如用的是 单机版
  single:
    host: 172.16.6.212:6379

spring:
  kafka:
    #bootstrap-servers: 192.168.6.102:9092,192.168.6.103:9092,192.168.6.104:9092
    #单机版用这个地址
    bootstrap-servers: 172.16.6.212:9092
    producer:
      batch-size: 26384
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.ByteArraySerializer
    consumer:
      group-id: consumer-prorps
      auto-offset-reset: latest
      session.timeout.ms: 60000
      enable-auto-commit: false
      auto-commit-interval: 1000
      max-poll-records: 600
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer
    #自定义 concurrency 为通道数，需要kafka分区配合使用。实例数量*concurrency=分区数量。需要用命为property主题增加分区
      concurrency: 10
      batch: true

#  mongodb设置
  data:
    mongodb:
      uri: mongodb://172.16.6.212:27017
      database: t9
kafkaConcurrency: 10

# DebugInterceptor
appDebug:
  debug: true

# SnowFlake 发号器 . 格式为 0-0 ，前面数字是 本实例启动的序号。 后面的数字是 整个dataCenter系统启动的序号。
#*******一般来说，启动多个使用snowflake 实例，只需要更改前面的序号。 两个参数的取值范围是 0-31 的整数******
snowFlakeParam:
  snowFlakeSetting: 0-1

# 系统管理模块的一些配置
systemSetting:
  # 登录前查应用配置信息，需要固化这个TenantId
  tenantId: 1
  logo:
    appLogoPath: /opt/data/files/images/appLogo
    loginLogoPath: /opt/data/files/images/loginLogo

# 动环系统数据推送    
pushDataUri: 

#nginx-rtmp应用url
nginx-rtmp-url: rtmp://ip:1935/mytv

# netty 门禁客户端
isOpenNettyClient: false
nettyClientIP: 127.0.0.1
nettyClientPort: 60006

# 门禁类型
accessDoorType: "Dr.Peng"